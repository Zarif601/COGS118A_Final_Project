{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Elevation', 'Aspect', 'Slope',\n",
    "       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n",
    "       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n",
    "       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points',\n",
    "       'Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3',\n",
    "       'Wilderness_Area4', 'Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n",
    "       'Soil_Type4', 'Soil_Type5', 'Soil_Type6', 'Soil_Type7', 'Soil_Type8',\n",
    "       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n",
    "       'Soil_Type13', 'Soil_Type14', 'Soil_Type15', 'Soil_Type16',\n",
    "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40',\n",
    "       'Cover_Type']\n",
    "      \n",
    "df = pd.read_csv('covtype.data', header = None, names = headers, na_values = ' ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Finding the most common cover type\n",
    "numeric = df['Cover_Type'].tolist()\n",
    "def most_common(numeric):\n",
    "    return max(set(numeric), key = numeric.count)\n",
    "\n",
    "print(most_common(numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the labels with 0's and 1's\n",
    "for i, j in enumerate(numeric):\n",
    "    if j == 2:\n",
    "        numeric[i] = 1\n",
    "    else:\n",
    "        numeric[i] = 0\n",
    "        \n",
    "df['Cover_Type'] = numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating features and labels\n",
    "X_p = df.iloc[:, :-1]\n",
    "y_p = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy vectors for train set\n",
    "logreg_accuracy_train = []\n",
    "randforest_accuracy_train = []\n",
    "knn_accuracy_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy vectors for test set\n",
    "logreg_accuracy = []\n",
    "randforest_accuracy = []\n",
    "knn_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# take all our penguin data, and reserve 20% of it for testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=5000,\n",
    "                                                    random_state=12345,\n",
    "                                                    stratify=y_p)\n",
    "\n",
    "\n",
    "# Initializing Classifiers\n",
    "clf1 = KNeighborsClassifier()\n",
    "clf2 = RandomForestClassifier(n_estimators = 1024)\n",
    "clf3 = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "# Declaring parameters\n",
    "K_list = np.array([n*20 for n in range(1,26)])\n",
    "F_list = np.array([1, 2, 4, 6, 8, 12, 16, 20])\n",
    "C_list = np.array([10**(-8), 10**(-7), 10**(-6), 10**(-5), 10**(-4), 10**(-3), 10**(-2), 10**(-1), \n",
    "                       10**(0), 10**(1), 10**(2), 10**(3), 10**(4)])\n",
    "\n",
    "# Building the pipelines\n",
    "pipe1 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf1)])\n",
    "\n",
    "pipe2 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf2)])\n",
    "\n",
    "pipe3 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf3)])\n",
    "\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid1 = [{'classifier__weights': ['uniform', 'distance'],\n",
    "                'classifier__n_neighbors': K_list}]\n",
    "\n",
    "param_grid2 = [{'classifier__max_features': F_list}]\n",
    "\n",
    "param_grid3 = [{'classifier__C': C_list}]\n",
    "\n",
    "\n",
    "# Setting up multiple GridSearchCV objects, 1 for each algorithm\n",
    "gridcvs = {}\n",
    "\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3),\n",
    "                            (pipe1, pipe2, pipe3),\n",
    "                            ('KNN', 'RandomForest', 'Logistic')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=3,\n",
    "                       cv=5, # just 2-fold inner loop, i.e. train/test\n",
    "                       verbose=0,\n",
    "                       return_train_score=True,\n",
    "                       refit='accuracy')\n",
    "    gridcvs[name] = gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer fold 1/5 | tuning KNN      | inner ACC 76.47% | outer ACC 78.62%\n",
      "outer fold 1/5 | tuning Logistic | inner ACC 74.97% | outer ACC 73.73%\n",
      "outer fold 1/5 | tuning RandomForest | inner ACC 81.70% | outer ACC 80.52%\n",
      "outer fold 2/5 | tuning KNN      | inner ACC 75.24% | outer ACC 80.22%\n",
      "outer fold 2/5 | tuning Logistic | inner ACC 73.84% | outer ACC 77.12%\n",
      "outer fold 2/5 | tuning RandomForest | inner ACC 80.70% | outer ACC 83.52%\n",
      "outer fold 3/5 | tuning KNN      | inner ACC 76.92% | outer ACC 76.10%\n",
      "outer fold 3/5 | tuning Logistic | inner ACC 74.70% | outer ACC 74.60%\n",
      "outer fold 3/5 | tuning RandomForest | inner ACC 81.45% | outer ACC 82.00%\n",
      "outer fold 4/5 | tuning KNN      | inner ACC 77.41% | outer ACC 73.17%\n",
      "outer fold 4/5 | tuning Logistic | inner ACC 74.83% | outer ACC 73.17%\n",
      "outer fold 4/5 | tuning RandomForest | inner ACC 81.78% | outer ACC 79.28%\n",
      "outer fold 5/5 | tuning KNN      | inner ACC 76.31% | outer ACC 76.28%\n",
      "outer fold 5/5 | tuning Logistic | inner ACC 74.31% | outer ACC 74.77%\n",
      "outer fold 5/5 | tuning RandomForest | inner ACC 81.08% | outer ACC 83.48%\n",
      "CPU times: user 56.6 s, sys: 4.93 s, total: 1min 1s\n",
      "Wall time: 49min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# ^^ this handy Jupyter magic times the execution of the cell for you\n",
    "\n",
    "cv_scores = {name: [] for name, gs_est in gridcvs.items()}\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# The outer loop for algorithm selection\n",
    "c = 1\n",
    "for outer_train_idx, outer_valid_idx in skfold.split(X_train,y_train):\n",
    "    for name, gs_est in sorted(gridcvs.items()):\n",
    "        print('outer fold %d/5 | tuning %-8s' % (c, name), end='')\n",
    "\n",
    "        # The inner loop for hyperparameter tuning\n",
    "        gs_est.fit(X_train.iloc[outer_train_idx], y_train.iloc[outer_train_idx])\n",
    "        y_pred = gs_est.predict(X_train.iloc[outer_valid_idx])\n",
    "        acc = accuracy_score(y_true=y_train.iloc[outer_valid_idx], y_pred=y_pred)\n",
    "        print(' | inner ACC %.2f%% | outer ACC %.2f%%' %\n",
    "              (gs_est.best_score_ * 100, acc * 100))\n",
    "        cv_scores[name].append(acc)\n",
    "\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN      | outer CV acc. 76.88% +\\- 2.404\n",
      "RandomForest | outer CV acc. 81.76% +\\- 1.662\n",
      "Logistic | outer CV acc. 74.68% +\\- 1.354\n",
      "\n",
      "KNN best parameters {'classifier__n_neighbors': 20, 'classifier__weights': 'distance'}\n",
      "RandomForest best parameters {'classifier__max_features': 4}\n",
      "Logistic best parameters {'classifier__C': 10.0}\n"
     ]
    }
   ],
   "source": [
    "# Looking at the results\n",
    "for name in cv_scores:\n",
    "    print('%-8s | outer CV acc. %.2f%% +\\- %.3f' % (\n",
    "          name, 100 * np.mean(cv_scores[name]), 100 * np.std(cv_scores[name])))\n",
    "print()\n",
    "for name in cv_scores:\n",
    "    print('{} best parameters'.format(name), gridcvs[name].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 77.50% (average over CV test folds)\n",
      "Best Parameters: {'classifier__n_neighbors': 20, 'classifier__weights': 'distance'}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 76.98%\n",
      "\n",
      "Accuracy 82.00% (average over CV test folds)\n",
      "Best Parameters: {'classifier__max_features': 16}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 82.23%\n",
      "\n",
      "Accuracy 74.36% (average over CV test folds)\n",
      "Best Parameters: {'classifier__C': 0.1}\n",
      "Training Accuracy: 75.02%\n",
      "Test Accuracy: 75.05%\n"
     ]
    }
   ],
   "source": [
    "# Fitting a model to the whole training set\n",
    "# using the \"best\" KNN algorithm\n",
    "best_algo = gridcvs['KNN']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['KNN'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "knn_accuracy.append(test_acc)\n",
    "knn_accuracy_train.append(train_acc)\n",
    "\n",
    "# using the \"best\" RandomForest algorithm\n",
    "best_algo = gridcvs['RandomForest']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "print('\\nAccuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['RandomForest'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "randforest_accuracy.append(test_acc)\n",
    "randforest_accuracy_train.append(train_acc)\n",
    "\n",
    "# using the \"best\" Logistic algorithm\n",
    "best_algo = gridcvs['Logistic']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "\n",
    "print('\\nAccuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['Logistic'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "logreg_accuracy.append(test_acc)\n",
    "logreg_accuracy_train.append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7697964625736964\n",
      "0.8223422428699402\n",
      "0.7504895731338931\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy[0])\n",
    "print(randforest_accuracy[0])\n",
    "print(logreg_accuracy[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# take all our penguin data, and reserve 20% of it for testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=5000,\n",
    "                                                    random_state=54321,\n",
    "                                                    stratify=y_p)\n",
    "\n",
    "\n",
    "# Initializing Classifiers\n",
    "clf1 = KNeighborsClassifier()\n",
    "clf2 = RandomForestClassifier(n_estimators = 1024)\n",
    "clf3 = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "# Declaring parameters\n",
    "K_list = np.array([n*20 for n in range(1,26)])\n",
    "F_list = np.array([1, 2, 4, 6, 8, 12, 16, 20])\n",
    "C_list = np.array([10**(-8), 10**(-7), 10**(-6), 10**(-5), 10**(-4), 10**(-3), 10**(-2), 10**(-1), \n",
    "                       10**(0), 10**(1), 10**(2), 10**(3), 10**(4)])\n",
    "\n",
    "# Building the pipelines\n",
    "pipe1 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf1)])\n",
    "\n",
    "pipe2 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf2)])\n",
    "\n",
    "pipe3 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf3)])\n",
    "\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid1 = [{'classifier__weights': ['uniform', 'distance'],\n",
    "                'classifier__n_neighbors': K_list}]\n",
    "\n",
    "param_grid2 = [{'classifier__max_features': F_list}]\n",
    "\n",
    "param_grid3 = [{'classifier__C': C_list}]\n",
    "\n",
    "\n",
    "# Setting up multiple GridSearchCV objects, 1 for each algorithm\n",
    "gridcvs = {}\n",
    "\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3),\n",
    "                            (pipe1, pipe2, pipe3),\n",
    "                            ('KNN', 'RandomForest', 'Logistic')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=3,\n",
    "                       cv=5, # just 2-fold inner loop, i.e. train/test\n",
    "                       verbose=0,\n",
    "                       return_train_score=True,\n",
    "                       refit='accuracy')\n",
    "    gridcvs[name] = gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer fold 1/5 | tuning KNN      | inner ACC 76.24% | outer ACC 74.13%\n",
      "outer fold 1/5 | tuning Logistic | inner ACC 75.22% | outer ACC 74.13%\n",
      "outer fold 1/5 | tuning RandomForest | inner ACC 81.87% | outer ACC 82.32%\n",
      "outer fold 2/5 | tuning KNN      | inner ACC 76.09% | outer ACC 76.22%\n",
      "outer fold 2/5 | tuning Logistic | inner ACC 75.42% | outer ACC 75.62%\n",
      "outer fold 2/5 | tuning RandomForest | inner ACC 81.52% | outer ACC 82.72%\n",
      "outer fold 3/5 | tuning KNN      | inner ACC 75.33% | outer ACC 77.80%\n",
      "outer fold 3/5 | tuning Logistic | inner ACC 75.38% | outer ACC 76.30%\n",
      "outer fold 3/5 | tuning RandomForest | inner ACC 81.00% | outer ACC 82.20%\n",
      "outer fold 4/5 | tuning KNN      | inner ACC 76.58% | outer ACC 74.87%\n",
      "outer fold 4/5 | tuning Logistic | inner ACC 76.11% | outer ACC 74.07%\n",
      "outer fold 4/5 | tuning RandomForest | inner ACC 81.95% | outer ACC 80.38%\n",
      "outer fold 5/5 | tuning KNN      | inner ACC 75.61% | outer ACC 78.68%\n",
      "outer fold 5/5 | tuning Logistic | inner ACC 74.86% | outer ACC 76.28%\n",
      "outer fold 5/5 | tuning RandomForest | inner ACC 81.05% | outer ACC 83.28%\n",
      "CPU times: user 1min 14s, sys: 4.44 s, total: 1min 18s\n",
      "Wall time: 48min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# ^^ this handy Jupyter magic times the execution of the cell for you\n",
    "\n",
    "cv_scores = {name: [] for name, gs_est in gridcvs.items()}\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# The outer loop for algorithm selection\n",
    "c = 1\n",
    "for outer_train_idx, outer_valid_idx in skfold.split(X_train,y_train):\n",
    "    for name, gs_est in sorted(gridcvs.items()):\n",
    "        print('outer fold %d/5 | tuning %-8s' % (c, name), end='')\n",
    "\n",
    "        # The inner loop for hyperparameter tuning\n",
    "        gs_est.fit(X_train.iloc[outer_train_idx], y_train.iloc[outer_train_idx])\n",
    "        y_pred = gs_est.predict(X_train.iloc[outer_valid_idx])\n",
    "        acc = accuracy_score(y_true=y_train.iloc[outer_valid_idx], y_pred=y_pred)\n",
    "        print(' | inner ACC %.2f%% | outer ACC %.2f%%' %\n",
    "              (gs_est.best_score_ * 100, acc * 100))\n",
    "        cv_scores[name].append(acc)\n",
    "\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN      | outer CV acc. 76.34% +\\- 1.713\n",
      "RandomForest | outer CV acc. 82.18% +\\- 0.976\n",
      "Logistic | outer CV acc. 75.28% +\\- 0.994\n",
      "\n",
      "KNN best parameters {'classifier__n_neighbors': 20, 'classifier__weights': 'distance'}\n",
      "RandomForest best parameters {'classifier__max_features': 16}\n",
      "Logistic best parameters {'classifier__C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Looking at the results\n",
    "for name in cv_scores:\n",
    "    print('%-8s | outer CV acc. %.2f%% +\\- %.3f' % (\n",
    "          name, 100 * np.mean(cv_scores[name]), 100 * np.std(cv_scores[name])))\n",
    "print()\n",
    "for name in cv_scores:\n",
    "    print('{} best parameters'.format(name), gridcvs[name].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 76.16% (average over CV test folds)\n",
      "Best Parameters: {'classifier__n_neighbors': 20, 'classifier__weights': 'distance'}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 77.13%\n",
      "\n",
      "Accuracy 82.14% (average over CV test folds)\n",
      "Best Parameters: {'classifier__max_features': 12}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 82.33%\n",
      "\n",
      "Accuracy 75.36% (average over CV test folds)\n",
      "Best Parameters: {'classifier__C': 10.0}\n",
      "Training Accuracy: 76.14%\n",
      "Test Accuracy: 74.97%\n"
     ]
    }
   ],
   "source": [
    "# Fitting a model to the whole training set\n",
    "# using the \"best\" KNN algorithm\n",
    "best_algo = gridcvs['KNN']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['KNN'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "knn_accuracy.append(test_acc)\n",
    "knn_accuracy_train.append(train_acc)\n",
    "\n",
    "# using the \"best\" RandomForest algorithm\n",
    "best_algo = gridcvs['RandomForest']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "print('\\nAccuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['RandomForest'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "randforest_accuracy.append(test_acc)\n",
    "randforest_accuracy_train.append(train_acc)\n",
    "\n",
    "# using the \"best\" Logistic algorithm\n",
    "best_algo = gridcvs['Logistic']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "\n",
    "print('\\nAccuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['Logistic'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "logreg_accuracy.append(test_acc)\n",
    "logreg_accuracy_train.append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7713051116990618\n",
      "0.8233127087630119\n",
      "0.7497447969833961\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy[1])\n",
    "print(randforest_accuracy[1])\n",
    "print(logreg_accuracy[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# take all our penguin data, and reserve 20% of it for testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_p, y_p,\n",
    "                                                    train_size=5000,\n",
    "                                                    random_state=13245,\n",
    "                                                    stratify=y_p)\n",
    "\n",
    "\n",
    "# Initializing Classifiers\n",
    "clf1 = KNeighborsClassifier()\n",
    "clf2 = RandomForestClassifier(n_estimators = 1024)\n",
    "clf3 = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "# Declaring parameters\n",
    "K_list = np.array([n*20 for n in range(1,26)])\n",
    "F_list = np.array([1, 2, 4, 6, 8, 12, 16, 20])\n",
    "C_list = np.array([10**(-8), 10**(-7), 10**(-6), 10**(-5), 10**(-4), 10**(-3), 10**(-2), 10**(-1), \n",
    "                       10**(0), 10**(1), 10**(2), 10**(3), 10**(4)])\n",
    "\n",
    "# Building the pipelines\n",
    "pipe1 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf1)])\n",
    "\n",
    "pipe2 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf2)])\n",
    "\n",
    "pipe3 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf3)])\n",
    "\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid1 = [{'classifier__weights': ['uniform', 'distance'],\n",
    "                'classifier__n_neighbors': K_list}]\n",
    "\n",
    "param_grid2 = [{'classifier__max_features': F_list}]\n",
    "\n",
    "param_grid3 = [{'classifier__C': C_list}]\n",
    "\n",
    "\n",
    "# Setting up multiple GridSearchCV objects, 1 for each algorithm\n",
    "gridcvs = {}\n",
    "\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3),\n",
    "                            (pipe1, pipe2, pipe3),\n",
    "                            ('KNN', 'RandomForest', 'Logistic')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                       param_grid=pgrid,\n",
    "                       scoring='accuracy',\n",
    "                       n_jobs=3,\n",
    "                       cv=5, # just 2-fold inner loop, i.e. train/test\n",
    "                       verbose=0,\n",
    "                       return_train_score=True,\n",
    "                       refit='accuracy')\n",
    "    gridcvs[name] = gcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer fold 1/5 | tuning KNN      | inner ACC 75.29% | outer ACC 74.13%\n",
      "outer fold 1/5 | tuning Logistic | inner ACC 75.29% | outer ACC 71.73%\n",
      "outer fold 1/5 | tuning RandomForest | inner ACC 80.40% | outer ACC 78.32%\n",
      "outer fold 2/5 | tuning KNN      | inner ACC 75.94% | outer ACC 76.02%\n",
      "outer fold 2/5 | tuning Logistic | inner ACC 74.37% | outer ACC 75.82%\n",
      "outer fold 2/5 | tuning RandomForest | inner ACC 80.77% | outer ACC 81.42%\n",
      "outer fold 3/5 | tuning KNN      | inner ACC 75.52% | outer ACC 75.20%\n",
      "outer fold 3/5 | tuning Logistic | inner ACC 74.65% | outer ACC 72.20%\n",
      "outer fold 3/5 | tuning RandomForest | inner ACC 80.95% | outer ACC 79.60%\n",
      "outer fold 4/5 | tuning KNN      | inner ACC 75.28% | outer ACC 76.58%\n",
      "outer fold 4/5 | tuning Logistic | inner ACC 74.53% | outer ACC 75.38%\n",
      "outer fold 4/5 | tuning RandomForest | inner ACC 80.70% | outer ACC 81.08%\n",
      "outer fold 5/5 | tuning KNN      | inner ACC 74.78% | outer ACC 77.78%\n",
      "outer fold 5/5 | tuning Logistic | inner ACC 73.68% | outer ACC 75.68%\n",
      "outer fold 5/5 | tuning RandomForest | inner ACC 79.98% | outer ACC 83.38%\n",
      "CPU times: user 50.5 s, sys: 5.07 s, total: 55.6 s\n",
      "Wall time: 46min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# ^^ this handy Jupyter magic times the execution of the cell for you\n",
    "\n",
    "cv_scores = {name: [] for name, gs_est in gridcvs.items()}\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# The outer loop for algorithm selection\n",
    "c = 1\n",
    "for outer_train_idx, outer_valid_idx in skfold.split(X_train,y_train):\n",
    "    for name, gs_est in sorted(gridcvs.items()):\n",
    "        print('outer fold %d/5 | tuning %-8s' % (c, name), end='')\n",
    "\n",
    "        # The inner loop for hyperparameter tuning\n",
    "        gs_est.fit(X_train.iloc[outer_train_idx], y_train.iloc[outer_train_idx])\n",
    "        y_pred = gs_est.predict(X_train.iloc[outer_valid_idx])\n",
    "        acc = accuracy_score(y_true=y_train.iloc[outer_valid_idx], y_pred=y_pred)\n",
    "        print(' | inner ACC %.2f%% | outer ACC %.2f%%' %\n",
    "              (gs_est.best_score_ * 100, acc * 100))\n",
    "        cv_scores[name].append(acc)\n",
    "\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN      | outer CV acc. 75.94% +\\- 1.235\n",
      "RandomForest | outer CV acc. 80.76% +\\- 1.715\n",
      "Logistic | outer CV acc. 74.16% +\\- 1.805\n",
      "\n",
      "KNN best parameters {'classifier__n_neighbors': 20, 'classifier__weights': 'distance'}\n",
      "RandomForest best parameters {'classifier__max_features': 4}\n",
      "Logistic best parameters {'classifier__C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Looking at the results\n",
    "for name in cv_scores:\n",
    "    print('%-8s | outer CV acc. %.2f%% +\\- %.3f' % (\n",
    "          name, 100 * np.mean(cv_scores[name]), 100 * np.std(cv_scores[name])))\n",
    "print()\n",
    "for name in cv_scores:\n",
    "    print('{} best parameters'.format(name), gridcvs[name].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 76.00% (average over CV test folds)\n",
      "Best Parameters: {'classifier__n_neighbors': 20, 'classifier__weights': 'distance'}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 77.41%\n",
      "\n",
      "Accuracy 81.34% (average over CV test folds)\n",
      "Best Parameters: {'classifier__max_features': 6}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 82.22%\n",
      "\n",
      "Accuracy 74.64% (average over CV test folds)\n",
      "Best Parameters: {'classifier__C': 100.0}\n",
      "Training Accuracy: 75.14%\n",
      "Test Accuracy: 75.59%\n"
     ]
    }
   ],
   "source": [
    "# Fitting a model to the whole training set\n",
    "# using the \"best\" KNN algorithm\n",
    "best_algo = gridcvs['KNN']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['KNN'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "knn_accuracy.append(test_acc)\n",
    "knn_accuracy_train.append(train_acc)\n",
    "\n",
    "# using the \"best\" RandomForest algorithm\n",
    "best_algo = gridcvs['RandomForest']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "print('\\nAccuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['RandomForest'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "randforest_accuracy.append(test_acc)\n",
    "randforest_accuracy_train.append(train_acc)\n",
    "\n",
    "# using the \"best\" Logistic algorithm\n",
    "best_algo = gridcvs['Logistic']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "\n",
    "print('\\nAccuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best Parameters: %s' % gridcvs['Logistic'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))\n",
    "logreg_accuracy.append(test_acc)\n",
    "logreg_accuracy_train.append(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7741297056311327\n",
      "0.8221842600501379\n",
      "0.755926959855003\n"
     ]
    }
   ],
   "source": [
    "print(knn_accuracy[2])\n",
    "print(randforest_accuracy[2])\n",
    "print(logreg_accuracy[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average KNN Test Accuracy:  1.0\n",
      "Average Random Forest Test Accuracy:  1.0\n",
      "Average Logistic Regression Test Accuracy:  0.7543333333333333\n"
     ]
    }
   ],
   "source": [
    "#report average train accuracy per classifier (with best parameter)\n",
    "print(\"Average KNN Test Accuracy: \", np.mean(knn_accuracy_train))\n",
    "print(\"Average Random Forest Test Accuracy: \", np.mean(randforest_accuracy_train))\n",
    "print(\"Average Logistic Regression Test Accuracy: \", np.mean(logreg_accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average KNN Test Accuracy:  0.7717437599679636\n",
      "Average Random Forest Test Accuracy:  0.82261307056103\n",
      "Average Logistic Regression Test Accuracy:  0.7520537766574308\n"
     ]
    }
   ],
   "source": [
    "#report average test accuracy per classifier (with best parameter)\n",
    "print(\"Average KNN Test Accuracy: \", np.mean(knn_accuracy))\n",
    "print(\"Average Random Forest Test Accuracy: \", np.mean(randforest_accuracy))\n",
    "print(\"Average Logistic Regression Test Accuracy: \", np.mean(logreg_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T - test for COV_TYPE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test between the different algorithms\n",
    "\n",
    "knn_forest = stats.ttest_ind(knn_accuracy, randforest_accuracy)\n",
    "\n",
    "forest_logistic = stats.ttest_ind(randforest_accuracy, logreg_accuracy)\n",
    "\n",
    "logistic_knn = stats.ttest_ind(logreg_accuracy, knn_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN and RandomForest:  Ttest_indResult(statistic=-38.59381360746943, pvalue=2.692397259865767e-06)\n",
      "\n",
      "RandomForest and Logistic Regression:  Ttest_indResult(statistic=35.63298684574943, pvalue=3.702247880570312e-06)\n",
      "\n",
      "Logistic Regression and KNN:  Ttest_indResult(statistic=-8.465804406727974, pvalue=0.0010668985208018861)\n"
     ]
    }
   ],
   "source": [
    "# Results of the T-tests\n",
    "\n",
    "print('KNN and RandomForest: ', knn_forest)\n",
    "print('\\nRandomForest and Logistic Regression: ', forest_logistic)\n",
    "print('\\nLogistic Regression and KNN: ', logistic_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
